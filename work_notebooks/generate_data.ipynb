{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e2816c-31eb-488b-bd8a-af3baf74b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/oa_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/Diploma/OneActor/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import argparse\n",
    "import yaml\n",
    "import pickle\n",
    "import json\n",
    "import shutil\n",
    "import sys\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(\"./diffusers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba6d4e3-3cc1-41ee-b9d8-c93bbbb5e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_images(images):\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    new_image = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        new_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width\n",
    "    return new_image\n",
    "\n",
    "def decode_latent(latent, pipeline):\n",
    "    with torch.no_grad():\n",
    "        pipeline.upcast_vae()\n",
    "        latent = latent.to(next(iter(pipeline.vae.post_quant_conv.parameters())).dtype)\n",
    "        image = pipeline.vae.decode(latent / pipeline.vae.config.scaling_factor, return_dict=False)[0]\n",
    "        image = pipeline.image_processor.postprocess(image, output_type='pil')[0]\n",
    "    return image\n",
    "\n",
    "def decode_and_cat(latent_list, pipeline):\n",
    "    images = []\n",
    "    for i in latent_list:\n",
    "        images.append(decode_latent(i, pipeline))\n",
    "    image = cat_images(images)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5374b246-84ae-4d18-8fcf-411848c6b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(\"PATH.json\",\"r\") as f:\n",
    "        ENV_CONFIGS = json.load(f)\n",
    "    with open(\"./config/gen_tune_inference_man.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af93f23c-ad58-4203-9919-49e5597145b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/oa_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/workspace/Diploma/OneActor/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/workspace/oa_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Fetching 19 files: 100%|██████████| 19/19 [00:24<00:00,  1.28s/it]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target prompt: A rugger adventurer with tousled hair, comic book stile \n"
     ]
    }
   ],
   "source": [
    "    device = config['device']\n",
    "    pipeline = DiffusionPipeline.from_pretrained(ENV_CONFIGS['paths']['sdxl_path']).to(device)\n",
    "    prompt = config['target_prompt'] + \" \" + config['add_target_prompt']\n",
    "    print(f\"Target prompt: {prompt}\")\n",
    "    guidance_scale = config['guidance_scale']\n",
    "    steps = config['steps']\n",
    "    generator = torch.manual_seed(config['g_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be91066d-7bb1-43ea-b46c-3cde123b0741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "    image, target_xt_list_, target_prompt_embeds, target_mid_ = pipeline(prompt, neg_prompt=config['target_neg_prompt'], \n",
    "                                                    num_inference_steps=steps, guidance_scale=guidance_scale, generator=generator,\n",
    "                                                    oneactor_save=True)\n",
    "    # save the target image\n",
    "    target_image = image.images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b097ff-dd0f-4242-b914-0929779d31e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n",
      "100%|██████████| 30/30 [00:24<00:00,  1.22it/s]\n",
      "100%|██████████| 30/30 [00:24<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "    base_image = []\n",
    "    mid_last_base = []\n",
    "    mid_last_base_long = []\n",
    "    if config['gen_base'] > 0:\n",
    "        num_base = 3\n",
    "        mid_last_base = []\n",
    "        for i in range(num_base):\n",
    "            image, xt_list_, prompt_embeds, mid_ = pipeline(prompt, neg_prompt=config['target_neg_prompt'],\n",
    "                                                            num_inference_steps=steps, guidance_scale=guidance_scale, generator=generator,\n",
    "                                                            oneactor_save=True)\n",
    "            base_image.append(image.images[0])\n",
    "            mid_last_base.append(mid_[-1].cpu())\n",
    "            mid_last_base_long.append([_.cpu() for _ in mid_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e61f8-b9b9-4f3d-950d-8efe53239f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (oa_venv)",
   "language": "python",
   "name": "oa_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
