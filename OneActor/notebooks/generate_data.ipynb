{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27fa6677-e821-405d-af08-7704bde3d5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/oa_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/Diploma/OneActor/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/workspace/Diploma/OneActor/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/workspace/Diploma/OneActor/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from consistory_run import load_pipeline, run_anchor_generation\n",
    "from consistory_utils import StoryPipelineStore\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import json\n",
    "import argparse\n",
    "import logging\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def find_token_ids(tokenizer, prompt, words):\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "    ids = []\n",
    "    if isinstance(words, str):\n",
    "                  words = [words]\n",
    "    for word in words:\n",
    "        for i, token in enumerate(tokens):\n",
    "            if tokenizer.decode(token) == word:\n",
    "                ids.append(i)\n",
    "                break\n",
    "    assert len(ids) != 0 , 'Cannot find the word in the prompt.'\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a5c0fd-374e-425c-9dcf-9acf227f1ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/oa_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/workspace/Diploma/OneActor/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 15.64it/s]\n",
      "/workspace/oa_venv/lib/python3.10/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 50)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/workspace/Diploma/OneActor/diffusers/models/lora.py:358: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(\n",
      "/workspace/Diploma/OneActor/diffusers/utils/torch_utils.py:106: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at ../aten/src/ATen/EmptyTensor.cpp:41.)\n",
      "  x_freq = fftn(x, dim=(-2, -1))\n",
      "/workspace/oa_venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 50/50 [00:50<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "    config_path = 'config/config.yaml'\n",
    "    prompt_path = 'config/prompt-girl.yaml'\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    with open(prompt_path, \"r\") as f:\n",
    "        prompt = yaml.safe_load(f)\n",
    "\n",
    "    subject = prompt['target_prompt']\n",
    "    concept_token = [prompt['base']]\n",
    "    settings = [\"standing\"] * 3 + [\"sitting\"] * 3 + [\"walking\"] * 2\n",
    "    if 'g_seed' not in list(config.keys()):\n",
    "        seed = random.randint(0, 10000)\n",
    "    else:\n",
    "        seed = config['g_seed']\n",
    "    mask_dropout = 0.5\n",
    "    same_latent = False\n",
    "\n",
    "\n",
    "    os.makedirs(config['experiments_dir'], exist_ok=True)\n",
    "    now = datetime.now()\n",
    "\n",
    "    now = now.strftime(\"%y%m%d%H%M\")\n",
    "    now = str(now)\n",
    "    output_dir = f\"{config['experiments_dir']}/{now}_{concept_token[0]}\"\n",
    "\n",
    "    gpu = 0\n",
    "    story_pipeline = load_pipeline(gpu)\n",
    "    \n",
    "    story_pipeline_store = StoryPipelineStore()\n",
    "    token_id = find_token_ids(story_pipeline.tokenizer, subject, concept_token)\n",
    "\n",
    "    # Reset the GPU memory tracking\n",
    "    torch.cuda.reset_max_memory_allocated(gpu)\n",
    "\n",
    "    \n",
    "    random_settings = random.sample(settings, 4)\n",
    "    prompts = [f'{subject} {setting}' for setting in random_settings]\n",
    "    anchor_out_images, anchor_image_all, anchor_cache_first_stage = \\\n",
    "            run_anchor_generation(story_pipeline, prompts[:6], concept_token, \n",
    "                           seed=seed, mask_dropout=mask_dropout, same_latent=same_latent,\n",
    "                           cache_cpu_offloading=True, story_pipeline_store=story_pipeline_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "931ec8d9-134c-43de-9fbd-ae9b6c99cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    data_list = {}\n",
    "    image_list = {}\n",
    "\n",
    "    n = 0\n",
    "    for i in range(len(story_pipeline_store.first_stage.images)):\n",
    "        n_samples = len(story_pipeline_store.first_stage.images[i])\n",
    "        for j in range(n_samples):\n",
    "            image_list[f\"img_{n}\"] = story_pipeline_store.first_stage.images[i][j]\n",
    "            mask = 1 - story_pipeline_store.first_stage.nn_distances[i][64].reshape(n_samples,n_samples,64,64)[j]\n",
    "            mask = torch.cat([mask[:j],mask[j+1:]]) \n",
    "            mask = mask.mean(dim=0)\n",
    "                    \n",
    "            data_list[f\"img_{n}\"] = {\n",
    "                'xt':[_xt_save[j:j+1] for _xt_save in story_pipeline_store.first_stage.xt_save[i]],\n",
    "                'h_mid':[_mid_save[j::n_samples]  for _mid_save in story_pipeline_store.first_stage.mid_save_list[i]],\n",
    "                'prompt_embed':story_pipeline_store.first_stage.prompt_embeds[i][j::n_samples],\n",
    "                'mask_64': mask, # sum\n",
    "                'prompt': story_pipeline_store.first_stage.prompt[i][j], \n",
    "                'concept_token': concept_token \n",
    "            }\n",
    "            n += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (oa_venv)",
   "language": "python",
   "name": "oa_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
